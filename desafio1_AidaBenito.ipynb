{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Vectorización\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np\n","from math import log10"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"PUbfVnzIIoMj"},"outputs":[],"source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"]},{"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"3ZqTOZzDI7uv"},"outputs":[{"data":{"text/plain":["array(['es', 'hoy', 'gracias', 'el', 'que', 'martes', 'muchas', 'dia',\n","       'de'], dtype='<U7')"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["def obtener_terminos(corpus):\n","    corpus_split = [corpus[i].split() for i in range(len(corpus))]\n","    corpus_set = {termino for documento in corpus_split for termino in documento}\n","    terminos = np.array(list(corpus_set))\n","    return (terminos)\n","\n","terminos= obtener_terminos(corpus)\n","terminos\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["ohe_matrix = np.zeros((len(corpus),len(terminos)))"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["(3, 9)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["ohe_matrix.shape"]},{"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Os0AAQo6I6Z1"},"outputs":[{"name":"stdout","output_type":"stream","text":["corpus: ['que dia es hoy' 'martes el dia de hoy es martes' 'martes muchas gracias']\n","terminos: ['es' 'hoy' 'gracias' 'el' 'que' 'martes' 'muchas' 'dia' 'de']\n"]},{"data":{"text/plain":["array([[1., 1., 0., 0., 1., 0., 0., 1., 0.],\n","       [1., 1., 0., 1., 0., 1., 0., 1., 1.],\n","       [1., 0., 1., 0., 0., 1., 1., 0., 0.]])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["ohe_matrix = np.zeros((len(corpus),len(terminos)))\n","for t,termino in enumerate(terminos):\n","    for d,documento in enumerate(corpus):\n","        if termino in documento:\n","            ohe_matrix[d,t]=1\n","print(f\"corpus: {corpus}\")\n","print(f\"terminos: {terminos}\")\n","ohe_matrix\n","        "]},{"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"yqij_7eHJbUi"},"outputs":[{"name":"stdout","output_type":"stream","text":["corpus: ['que dia es hoy' 'martes el dia de hoy es martes' 'martes muchas gracias']\n","terminos: ['es' 'hoy' 'gracias' 'el' 'que' 'martes' 'muchas' 'dia' 'de']\n","[[1. 1. 0. 0. 1. 0. 0. 1. 0.]\n"," [1. 1. 0. 1. 0. 2. 0. 1. 1.]\n"," [0. 0. 1. 0. 0. 1. 1. 0. 0.]]\n"]}],"source":["def vect_frec(corpus,terminos):\n","    freq_matrix = np.zeros((len(corpus),len(terminos)))\n","    for t,termino in enumerate(terminos):\n","        for d,documento in enumerate(corpus):\n","            freq_matrix [d,t]= np.sum(np.array(documento.split()) == termino)\n","    return freq_matrix\n","\n","\n","print(f\"corpus: {corpus}\")\n","print(f\"terminos: {terminos}\")\n","freq_matrix = vect_frec(corpus,terminos)\n","print(freq_matrix)\n","        \n"]},{"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Data una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"waG_oWtpJjRw"},"outputs":[{"data":{"text/plain":["array([[0.17609126, 0.17609126, 0.        , 0.        , 0.47712125,\n","        0.        , 0.        , 0.17609126, 0.        ],\n","       [0.17609126, 0.17609126, 0.        , 0.47712125, 0.        ,\n","        0.35218252, 0.        , 0.17609126, 0.47712125],\n","       [0.        , 0.        , 0.47712125, 0.        , 0.        ,\n","        0.17609126, 0.47712125, 0.        , 0.        ]])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["\n","#TFIDF = TF * IDF\n","\n","def tfidf(corpus,terminos):\n","    tfidf = np.zeros((len(corpus),len(terminos)))\n","    n = len(corpus)\n","\n","\n","    df = np.zeros(len(terminos))\n","    for t,termino in enumerate(terminos):\n","        for documento in corpus:\n","            if termino in documento.split():\n","                df[t]=df[t]+1\n","\n","\n","    for t,termino in enumerate(terminos):\n","        for d,documento in enumerate(corpus):\n","            tfidf[d,t]=freq_matrix[d,t]*log10(n/df[t])\n","    return tfidf\n","\n","tfidf(corpus,terminos)"]},{"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"CZdiop6IJpZN"},"outputs":[{"name":"stdout","output_type":"stream","text":["que dia es hoy\n","martes el dia de hoy es martes\n","martes muchas gracias\n"]}],"source":["def order_cosine_similarity(corpus, index):\n","    terminos = obtener_terminos(corpus)\n","    \n","    tf_vectors = vect_frec(corpus,terminos)\n","    reference_vector = tf_vectors[index]\n","    similarity_scores = [cosine_similarity(reference_vector, doc) for doc in tf_vectors]\n","    document_indices = sorted(range(len(similarity_scores)), key=lambda i: similarity_scores[i], reverse=True)\n","    sorted_documents = [corpus[i] for i in document_indices]\n","    return sorted_documents\n","\n","sorted_documents = order_cosine_similarity(corpus, 0)\n","\n","for doc in sorted_documents:\n","    print(doc)\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["['es un dia lluvioso',\n"," 'es un dia maravilloso',\n"," 'la entropia del universo aumenta dia a dia']"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["corpus = np.array(['es un dia maravilloso', 'es un dia lluvioso', 'la entropia del universo aumenta dia a dia'])\n","order_cosine_similarity(corpus, 1)\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5fRYTpympAwJSVbric6dW","collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
